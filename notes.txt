Feature engineering
-------------------
Would like to derive variables e.g. density, momentum from known data
See load-grid-info.py to get pressures at altitude levels

# Altitude levels in hPa from ClimSim-main\grid_info\ClimSim_low-res_grid-info.nc
level_pressure_hpa = [0.07834781133863082, 0.1411083184744011, 0.2529232969453412, 0.4492506351686618, 0.7863461614709879, 1.3473557602677517, 2.244777286900205, 3.6164314830257718, 5.615836425337344, 8.403253219853443, 12.144489352066294, 17.016828024303006, 23.21079811610005, 30.914346261995327, 40.277580662953575, 51.37463234765765, 64.18922841394662, 78.63965761131159, 94.63009200213703, 112.09127353988006, 130.97780378937776, 151.22131809551237, 172.67390465199267, 195.08770981962772, 218.15593476138105, 241.60037901222947, 265.2585152868483, 289.12232222921756, 313.31208711045167, 338.0069992368819, 363.37349177951705, 389.5233382784413, 416.5079218282233, 444.3314120123719, 472.9572063769364, 502.2919169181905, 532.1522731583445, 562.2393924639011, 592.1492760575118, 621.4328411158061, 649.689897132655, 676.6564846051039, 702.2421877859194, 726.4985894989197, 749.5376452869328, 771.4452171682528, 792.2342599534793, 811.8566751313328, 830.2596431972574, 847.4506530638328, 863.5359020075301, 878.7158746040692, 893.2460179738746, 907.3852125876941, 921.3543974831824, 935.3167171670306, 949.3780562075774, 963.5995994020714, 978.013432382012, 992.6355435925217]

Tips from others
----------------

Polars found to be much faster than pandas in saving very large .csv (though not
clear if forming dataframe included):
https://www.kaggle.com/competitions/leap-atmospheric-physics-ai-climsim/discussion/495128

Nice simple example code showing PyTorch feedforward model and submission:
https://www.kaggle.com/code/airazusta014/pytorch-nn
Another nice simple NN using Keras:
https://www.kaggle.com/code/ymatioun/leap-simple-nn


Ideas to progress
-----------------

o Figure out faster/cheaper validation test to avoid using GPU quota and quicker turnaround
o Understand physics of each target col better
o Does humidity have significant effect on heat capacity? And cloud/rain/snow content?
o Reciprocal of new features, e.g. heating in K/s will be inversely proportional to density
 for given heat input
o Deeper/alternative network structures
o CNN-type network that scans across altitude levels (mixed with those above and below)
o Batch-based training on whole dataset or much bigger subset
o Try other ML techniques apart from NN
o Would it help to remove more old feature columns?
o Would it help to group columns differently depending on technique?
o If big run dominated by data loading, could train different model variants simultaneously?


Scoring and why predictions zeroed for low-variance cols in example
-------------------------------------------------------------------

Uses sklearn.metrics.r2_score
Competition links to https://www.kaggle.com/code/jerrylin96/r2-score-default
Discussion https://www.kaggle.com/competitions/leap-atmospheric-physics-ai-climsim/discussion/495255
R2 is average across R2 for individual columns, but with weighting
R2 for one col = 1 - ( (sq resids sum of prediction) / ((true - avg true) sq sum))
So get R2=0 if just guess mean for column
If true values have very low variance, (true - avg true) -> 0 and R2 -> inf
R2=0 a lot better than wild value if a little bit off for low-variance columns, hence
guessing mean like sample code


Beucler et al
o Transformed relative humidity to specific humidity for much better generalisation
  https://colab.research.google.com/github/tbeucler/CBRAIN-CAM/blob/master/Climate_Invariant_Guide.ipynb
o Transformed temperature to a buoyancy metric, also improved but only with RH too
o Radiative effects: absorbtion of SW (visible), greenhouse trapping of LW (IR)
o Sensible heat flux: +ve from atm to surface (radiation, conduction, convection??)
o Latent heat flux: +ve for condensation on surface, -ve for evaporation from surface


Results from early expts
------------------------

Showed that it did a touch better with additional new features, and getting rid of some raw ones:

LEAP with feature engineering - Version 19
Complete · 4m ago · commit afda421d20 Multiplying by submission weights before modelling now
0.32041

LEAP with feature engineering - Version 18
Complete · 19h ago · commit c7b0cfa660 Understood R2 measure now and some sense of why sample code was zeroing (actually setting mean) for columns with low variance. Also reading as F64 before scaling.
0.30840

LEAP with feature engineering - Version 17
Complete · 9h ago · commit a34b29920 Going back to RMS y-normalisation in case change there somehow responsible for bad recent scores
-1.32174

LEAP with feature engineering - Version 16
Complete · 3m ago · Commit 7cef81edd SiLU activation, allowing larger 'good' values in columns
-2.34299

LEAP with feature engineering - Version 15 *** now using 30,000 training rows ***
Complete · 3m ago · Commit 3765366 zeroing crazy large-number cols but not zeroing out all 'low variance' ones
-0.39082

LEAP with feature engineering - Version 12  *** up to this point using 100,000 training rows ***
Complete · 2m ago · commit 265c9f3bac not zeroing out invariant result columns
-1037770694134379085769163933486585061126756728541364533486745413084161537962122674176.00000

LEAP with feature engineering - Version 11
Complete · 2m ago · commit 67fdcab66 with reciprocal density
0.34119

LEAP with feature engineering - Version 10
Complete · 3m ago · Commit 0d8d069 removed a few raw features
0.34286

LEAP with feature engineering - Version 9
Complete · 2m ago · commit fd0d97d93, first with relative humidity
0.26862

LEAP with feature engineering - Version 7
Complete · 4m ago · commit 34faf3590 again but with new features turned off for comparison
0.22994

LEAP with feature engineering - Version 6
Complete · 42m ago · commit 34faf35, 1000000 training rows failed I think, this is 100000
0.25368

LEAP with feature engineering - Version 4
Complete · 11h ago · f2a52c8 First attempts with some feature engineering on limited number of rows
0.23289