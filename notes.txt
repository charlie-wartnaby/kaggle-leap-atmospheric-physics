Feature engineering
-------------------
Would like to derive variables e.g. density, momentum from known data
See load-grid-info.py to get pressures at altitude levels

# Altitude levels in hPa from ClimSim-main\grid_info\ClimSim_low-res_grid-info.nc
level_pressure_hpa = [0.07834781133863082, 0.1411083184744011, 0.2529232969453412, 0.4492506351686618, 0.7863461614709879, 1.3473557602677517, 2.244777286900205, 3.6164314830257718, 5.615836425337344, 8.403253219853443, 12.144489352066294, 17.016828024303006, 23.21079811610005, 30.914346261995327, 40.277580662953575, 51.37463234765765, 64.18922841394662, 78.63965761131159, 94.63009200213703, 112.09127353988006, 130.97780378937776, 151.22131809551237, 172.67390465199267, 195.08770981962772, 218.15593476138105, 241.60037901222947, 265.2585152868483, 289.12232222921756, 313.31208711045167, 338.0069992368819, 363.37349177951705, 389.5233382784413, 416.5079218282233, 444.3314120123719, 472.9572063769364, 502.2919169181905, 532.1522731583445, 562.2393924639011, 592.1492760575118, 621.4328411158061, 649.689897132655, 676.6564846051039, 702.2421877859194, 726.4985894989197, 749.5376452869328, 771.4452171682528, 792.2342599534793, 811.8566751313328, 830.2596431972574, 847.4506530638328, 863.5359020075301, 878.7158746040692, 893.2460179738746, 907.3852125876941, 921.3543974831824, 935.3167171670306, 949.3780562075774, 963.5995994020714, 978.013432382012, 992.6355435925217]

Ideas to progress
-----------------

o Use Kaggle API to submit submission.csv if do good run locally
o Run on whole dataset even for limited number of epochs in case scores better
o Higher dropout proportion? Looks too smooth on Kaggle big run.
o Bring back normalisation layer(s)?
o Haven't explored optimiser, learning rate etc
o Deal properly with columns that are going to be zero anyway
o Understand physics of each target col better
o Does humidity have significant effect on heat capacity? And cloud/rain/snow content?
o Reciprocal of new features, e.g. heating in K/s will be inversely proportional to density
 for given heat input
o Deeper/alternative network structures
o Try other ML techniques apart from NN
o Would it help to remove more old feature columns?
o Would it help to group columns differently depending on technique?


Scoring and why predictions zeroed for low-variance cols in example
-------------------------------------------------------------------

Uses sklearn.metrics.r2_score
Competition links to https://www.kaggle.com/code/jerrylin96/r2-score-default
Discussion https://www.kaggle.com/competitions/leap-atmospheric-physics-ai-climsim/discussion/495255
R2 is average across R2 for individual columns, but with weighting
R2 for one col = 1 - ( (sq resids sum of prediction) / ((true - avg true) sq sum))
So get R2=0 if just guess mean for column
If true values have very low variance, (true - avg true) -> 0 and R2 -> inf
R2=0 a lot better than wild value if a little bit off for low-variance columns, hence
guessing mean like sample code


Beucler et al
o Transformed relative humidity to specific humidity for much better generalisation
  https://colab.research.google.com/github/tbeucler/CBRAIN-CAM/blob/master/Climate_Invariant_Guide.ipynb
o Transformed temperature to a buoyancy metric, also improved but only with RH too
o Radiative effects: absorbtion of SW (visible), greenhouse trapping of LW (IR)
o Sensible heat flux: +ve from atm to surface (radiation, conduction, convection??)
o Latent heat flux: +ve for condensation on surface, -ve for evaporation from surface


Results from early expts
------------------------

Showed that it did a touch better with additional new features, and getting rid of some raw ones:

At commit 42896a9aac, out of memory preprocessing test data on Kaggle. Locally with 10M rows:
Epoch 1, Validation Loss: 0.4515650928020477
Epoch 2, Validation Loss: 0.43092106863856317
Epoch 3, Validation Loss: 0.42092101737856863
Epoch 4, Validation Loss: 0.4152659673988819
Epoch 5, Validation Loss: 0.410844571813941

Current state at commit ebe569df, looks like it may go on for too long as no noise in validation score:
7363.7s	188	Validation loss decreased, saving new best model and resetting patience counter.
7417.9s	189	Epoch 28, Step 10, Training Loss: 0.4816
7471.9s	190	Epoch 28, Step 20, Training Loss: 0.4546
7525.8s	191	Epoch 28, Step 30, Training Loss: 0.4872
7579.6s	192	Epoch 28, Step 40, Training Loss: 0.4747

LEAP with feature engineering - Version 35
Complete · 3m ago · Commit 2c9a279 smallish test run with CNN approach and overhauled test output
With only: Validation Loss: 0.5902572572231293

0.35463
LEAP with feature engineering - Version 25
Complete · 3d ago · commit 755728af first test run with holo frame concept

0.28431

LEAP with feature engineering - Version 19
Complete · 4m ago · commit afda421d20 Multiplying by submission weights before modelling now
0.32041

LEAP with feature engineering - Version 18
Complete · 19h ago · commit c7b0cfa660 Understood R2 measure now and some sense of why sample code was zeroing (actually setting mean) for columns with low variance. Also reading as F64 before scaling.
0.30840

LEAP with feature engineering - Version 17
Complete · 9h ago · commit a34b29920 Going back to RMS y-normalisation in case change there somehow responsible for bad recent scores
-1.32174

LEAP with feature engineering - Version 16
Complete · 3m ago · Commit 7cef81edd SiLU activation, allowing larger 'good' values in columns
-2.34299

LEAP with feature engineering - Version 15 *** now using 30,000 training rows ***
Complete · 3m ago · Commit 3765366 zeroing crazy large-number cols but not zeroing out all 'low variance' ones
-0.39082

LEAP with feature engineering - Version 12  *** up to this point using 100,000 training rows ***
Complete · 2m ago · commit 265c9f3bac not zeroing out invariant result columns
-1037770694134379085769163933486585061126756728541364533486745413084161537962122674176.00000

LEAP with feature engineering - Version 11
Complete · 2m ago · commit 67fdcab66 with reciprocal density
0.34119

LEAP with feature engineering - Version 10
Complete · 3m ago · Commit 0d8d069 removed a few raw features
0.34286

LEAP with feature engineering - Version 9
Complete · 2m ago · commit fd0d97d93, first with relative humidity
0.26862

LEAP with feature engineering - Version 7
Complete · 4m ago · commit 34faf3590 again but with new features turned off for comparison
0.22994

LEAP with feature engineering - Version 6
Complete · 42m ago · commit 34faf35, 1000000 training rows failed I think, this is 100000
0.25368

LEAP with feature engineering - Version 4
Complete · 11h ago · f2a52c8 First attempts with some feature engineering on limited number of rows
0.23289